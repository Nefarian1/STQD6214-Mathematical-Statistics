






































#T1~~~ç®€å•è¿ç®—ï¼ŒçŸ©é˜µ
#T2~~~ç»™æ•°æ®ï¼Œå‡ ä¸ªæ•°æ®ä¸²åšæˆæ¡†ï¼Œçœ‹åˆ—åï¼Œå‰å‡ è¡Œï¼Œä¸­ä½æ•°å¹³å‡å•¥çš„ï¼Œå€¾æ–œ
#T3~~~æ•£ç‚¹å›¾ï¼Œæ¡å½¢å›¾ï¼ŒæŠ˜çº¿å›¾ï¼Œç®±å‹å›¾ç­‰ç­‰
#T4~~~åˆ†æï¼Œå‡è®¾æ€§æ£€éªŒå’ŒPå€¼ï¼Œçº¿æ€§å›å½’ï¼ˆç³»æ•°ï¼‰ï¼ŒANOVAï¼ˆæ˜Ÿå·å¤šï¼Œpè¶Šå°ï¼Œæ‹’ç»åŸå‡è®¾ï¼‰
#T5~~~è›‹ç–¼æ–¹ç¨‹å’Œå¾ªç¯
#T6~~~Poissonï¼ŒMonte Carlo integrationï¼ŒRejection sampling(Beta)
#EX~~~Galton board,  Chebyshevâ€™s theorem



# T1
# 1-1 Evaluate the following expressions.
#12.3 + 232.2
12.3+232.2
#log(e^2 + 3)
log(exp(2)+3)
#sin(ğœ‹/4+ 3)
sin(pi/4+3)
#tan^âˆ’1(1.3^2)
atan(1.3^2)

# 1-2 Let ğ‘¥ = 2.3 and ğ‘¦ = 3.1. Evaluate the following expressions.
x <- 2.3
y <- 3.1
#æ ¹å·ä¸‹(x^4-5y)
sqrt(x^4-5*y)
#e^x-3x+y^x
exp(x) - 3*x + y^x
#cos^-1(x/y)
acos(x/y)
#log(z+3/z) where z=x^2-log(10y)
z <- x^2 - log(10*y)
log(z+3/z)

# 1-3 Let ğ‘¥ = 2.3 and ğ‘¦ = 3.1. 
#Determine whether the following expressions are true or false.
x <- 2.3
y <- 3.1
#3ğ‘¥ > 2ğ‘¦
3*x > 2*y
#x^y<=y^x and 3^x+y^2.2
(x^y <= y^x) & (3^x > y^2.2)
#cos(ğ‘¥) = 0 or sin(ğ‘¦) > 0
(cos(x) == 0) | (sin(y)>0)

# 1-4 Let ğ’™ and ğ’š be vectors where ğ’™ = (6,4,3,20) and ğ’š = (12,46,2,1). 
#Evaluate the following expressions.
x <- c(6,4,3,20)
y <- c(12,46,2,1)
#x + 2y
x + 2*y
#âˆ‘ (i=1~4)xiyi
sum(x*y)
#max(ğ’›) where the ğ‘–th component of zi=xi^2-10yi,
#Which component gives this maximum value of z?
z <- x^2 - 10*y
max(z)
which.max(z)
#How would you code to get the components of ğ’š that is bigger than 10?
y[y>10]
#Run this following code: c(x, y). What do you think happen here?
c(x,y)#It combines the vector ğ‘¥ and ğ‘¦ into one vector.ç»„åˆæˆä¸€ä¸ªå‘é‡
#Run this following code: sum(x[x>5]). What do you think happen here?
sum(x[x>5])#It calculates the sum of ğ‘¥ with values greater than 5.å¤§äº5çš„xçš„å’Œ
#Run this following code: sum(x>5). What do you think happen here?
sum(x>5)#æ•°é‡The code calculates the number of component in ğ‘¥ with values greater than 5.

# 1-5 Without using only the c() function, create the following:
#A vector containing integers from -10 to 10.
-10:10
#A sequence of numbers from 0 to 100 where the length of sequence is 1000.
seq(from=0, to=100, length.out=1000)
#A vector of 0â€™s with length 10.
rep(0, 10)# or vector("numeric", 10)
#The vector (â€œAâ€, â€œBâ€, â€œCâ€, â€œAâ€, â€œBâ€, â€œCâ€, â€œAâ€, â€œBâ€, â€œCâ€).
rep(c("A", "B", "C"), times=3)
#The vector (â€œAâ€, â€œAâ€, â€œAâ€, â€œBâ€, â€œBâ€, â€œBâ€, â€œCâ€, â€œCâ€, â€œCâ€).
rep(c("A", "B", "C"), each=3)

# 1-6 Let ğ´ = [21 3 ] and ğµ = [12 4 ]. Answer the following questions.
#              [2  14]          [5  51]
#Assign the variables A and B as the matrix above. 
#Run this following code: class(A). What do you get here?
A <- matrix(c(21,3,2,14), ncol=2, byrow=TRUE)
B <- matrix(c(12,5,45,1), ncol=2, byrow=TRUE)
class(A)
#Evaluate A+B
A+B#å åŠ 
#Evaluate AB
A %*% B
#Evaluate A^-1
solve(A)
#Evaluate (A^T B)^-1
solve(t(A) %*% B)

# 1-7 Let D = [3  52  7]and x=[75] Assign the variables D and x as given. 
#             [2  10  1]      [2 ]
#Let E be a 2 Ã— 4 matrix where the first 3 columns of E is the same as D
#and the fourth column of E is the same as x. How would you code the matrix ğ¸ in R?
D <- matrix(c(3,52,7,2,10,1), nrow=2, byrow=TRUE)
x <- matrix(c(75,2),nrow=2)
E <- cbind(D,x)
#Let F be a 2 Ã— 2 matrix where F is the first two columns of D.
#How would you get matrix F using R?
F <- D[,c(1,2)]







# T2
# 2-1-a Using the data.frame() function,
#create a new data frame named TIRES using the following data:
x <- c(30,30,31,31,32,32,33,33,34,34,35,35,36,36)
y <- c(29.5,30.2,32.1,34.5,36.3,35,38.2,37.6,37.7,
       36.1,33.6,34.2,26.8,27.4)
TIRES <- data.frame(x=x, y=y)
# 2-1-b Using names(), change the variable names in the data frame 
#such that the variable x is changed to pressure, and the variable y is changed to mileage.
names(TIRES) <- c("pressure", "mileage")
# 2-1-c Print out the first 4 rows.
TIRES[1:4,]#or head(TIRES, n=4)
# 2-1-d Print out the rows in the dataset with mileage is greater than 35
subset(TIRES, mileage>35)#or TIRES[TIRES$mileage>35,]
# 2-1-e Print out your current working directory.
getwd()
# 2-1-f Using the write.csv() function, save the data frame into a CSV file. Verify the file.
write.csv(TIRES, file="Question1e.csv",
          row.names=FALSE)

# 2-2 Using read.table() or read.csv() functions, import the dataset into R,
#and assign it to a data frame named TestScore.
TestScore <- read.csv("TestScore.csv")
# What are the available variables in the data frame?çœ‹å˜é‡æˆ–åˆ—å
names(TestScore)
# Print out the 8th row of the data frame.
TestScore[8,]
# Using the describe() function in psych package,
# print out the summary statistics for the data frame.
library(psych)
describe(TestScore)
# Calculate the mean, median, and variance for the GPAs of the students.
mean(TestScore$GPA)
median(TestScore$GPA)
var(TestScore$GPA)
# Calculate the first and third quartiles for the GPAs of students, and its interquartile range.
quantile(TestScore$GPA, c(0.25,0.75))
IQR(TestScore$GPA)
# Calculate skewness and kurtosis for the GPAs of the students.
# Is the data skewed to the left or to the right? Is the data platykurtic or leptokurtic?
library(e1071)
skewness(TestScore$GPA)#Skewed to the right (but only slightly), since the skewness is positiveï¼ˆæ­£æ•°ï¼‰. 
kurtosis(TestScore$GPA)#Platykurtic since the kurtosis is negativeï¼ˆè´Ÿæ•°ï¼‰.
# Print out all rows containing students from Class B.
#Assign these values to another data frame.
subset(TestScore, Class=="B")
#or
TestScore[TestScore$Class=="B",]
classB <- subset(TestScore, Class=="B")
# Calculate the mean, median, and variance for the IQ of students in Class B.
mean(classB$IQ)
median(classB$IQ)
var(classB$IQ)
# Calculate the range for the IQ of students in Class B.
max(classB$IQ) - min(classB$IQ)
# Using quantile(), what is minimum value for the top 15% of studentsâ€™ study hours?
quantile(TestScore$StudyHours, probs=0.85)
# Find the mode for the study hours of the students.
table(TestScore$StudyHours)
names(table(TestScore$StudyHours))[which.max(
      table(TestScore$StudyHours))]

# 2-3 Import the dataset into R.
property_sales <- read.csv(file.choose())
# Print out the name of all the available variables in the dataset.
names(property_sales)
# Print out the first 6 rows of the dataset.
head(property_sales, 6)#property_sales[1:6,]
# Using the table() function on the neighbourhood variable,
#print out how many observations there are for each neighbourhood.
#Which neighourhood has the highest frequency?
table(property_sales$Neighbourhood)
# What is the highest and lowest sales price in the dataset?
#Calculate the value for its range.
max(property_sales$Sales)
min(property_sales$Sales)
max(property_sales$Sales)-min(property_sales$Sales)
# Calculate the mean, median and variance for the sales price of all the properties.
mean(property_sales$Sales)
median(property_sales$Sales)
var(property_sales$Sales)
# Calculate the mean, median and variance for the sales price of the properties in Davis Isles.
Davis <- subset(property_sales,
                Neighbourhood == "DavisIsles")
mean(Davis$Sales)
median(Davis$Sales)
var(Davis$Sales)
# Calculate skewness and kurtosis for the sales price in Davis Isles.
#Is the data skewed to the left or to the right? Is the data platykurtic or leptokurtic?
library(e1071)
skewness(Davis$Sales)
kurtosis(Davis$Sales)
# Calculate the first, second, and third quartiles for the appraised land value
#for the properties in Cheval. Calculate its interquartile range.
Cheval <- subset(property_sales, 
                 Neighbourhood=="Cheval")
quantile(Cheval$Land.value, c(0.25,0.5,0.75))
IQR(Cheval$Land.value)







# T3
# 3-1 Run the following code first to assign the values to each variable.
year <- 2012:2019
engineering <- c(20397, 21432, 22206, 20778, 22362, 23669, 23400, 24137)
science <- c(10680, 11561, 11690, 10592, 11858, 13100, 11796, 12267)
technology <- c(5124, 6679, 6828, 6200, 9553, 10809, 11396, 10682)
# Produce a scatterplot between the number of engineering students and the years
# Modify your code to include a suitable title and the labels for x-axis and y-axis.
plot(x=year, y=engineering, main="Plot of 
    engineeering students over the years", 
     ylab="Number of students", xlab="Years")#or plot(engineering~year)
# How would you modify your code if you want to
#draw lines connecting each subsequent point?
plot(x=year, y=engineering, main="Plot of 
    engineeering students over the years", 
     ylab="Number of students", xlab="Years", type="o")
# Play around and experiment with the arguments for the plot() function.
plot(x=year, y=engineering, main="Plot of 
    engineeering students over the years", 
     ylab="Number of students", xlab="Years", type="o", col="magenta", 
     pch=3, cex=1.5, lty=2, lwd=1, ylim=c(20000,30000))
# Now, using the functions points() or lines(),
#add the plots showing the number of science and technology students for each year to the existing diagram.
#The plot should now consist of three lines/points, one for each category.
#Make sure the colours and characters used for each category are distinguishable.
#You may need to modify the ylim in the original plot() to fit all the lines/points.
plot(x=year, y=engineering, main="Plot of number of 
     students over the years", ylab="Number of students", 
     xlab="Years", type="o", col="magenta", pch=3, 
     cex=1.5, lty=2, lwd=1, ylim=c(5000,25000))
points(x=year, y=science, type="o", col="blue")
points(x=year, y=technology, type="o", 
       col="darkgreen", pch=2)
# Using the legend() function, add suitable legends in the plot to show what each line/point refers to.
plot(x=year, y=engineering, main="Plot of number of 
     students over the years", ylab="Number of students", 
     xlab="Years", type="o", col="magenta", pch=3, 
     cex=1.5, lty=2, lwd=1, ylim=c(5000,25000))
points(x=year, y=science, type="o", col="blue")
points(x=year, y=technology, type="o", 
       col="darkgreen", pch=2)
#å’Œä¸Šé¢ä¸€æ ·ï¼Œåªæ˜¯å¤šäº†ä¸‹é¢è¿™æ®µ
# "bottomright"æ˜¯å³ä¸‹è§’ï¼Œå·¦ä¸Šè§’æ˜¯"topright"
legend(x="bottomright", legend=c("Engineering", 
                                 "Science", "Technology"), pch=c(3,1,2), 
       col=c("magenta","blue","darkgreen"), lty=c(2,1,1))

# 3-2 Load the mtcars dataset by running data(mtcars) in the R console.
# Draw a histogram for the miles per gallon (mpg) of the cars.
data(mtcars)
hist(mtcars$mpg, main="Histogram of mpg", xlab="mpg")
# The variable am is 0 if the car has an automatic transmission,
#and 1 if the car has a manual transmission.
#Draw a side-by-side boxplot to compare the miles per gallon (mpg) and the transmission of the car (am). Modify the labels for the boxplot.
boxplot(mpg~am, data=mtcars, 
        names=c("Automatic","Manual"), xlab="Transmission", 
        main="Boxplot of transmission vs mpg")
# Draw a scatterplot for miles per gallon (mpg) vs displacement (disp).
plot(mpg~disp, data=mtcars, main="Plot of mpg vs disp")
#æˆ–è€…plot(x=mtcars$disp, y=mtcars$mpg, main="Plot of mpg vs disp")
# Draw a scatterplot matrix with the variables mpg, disp, hp, and wt in the diagram.
pairs(~mpg+disp+hp+wt, mtcars)
# The code table(mtcars$gear) gives the frequency of cars
#with each of the number of forward gears.
#Using this frequency, draw a bar graph for the number of cars with the number of forward gears.
barplot(table(mtcars$gear), xlab="Gear", 
        ylab="Frequency", main="Bar graph of gear frequency")

# 3-3-a Draw a scatterplot matrix to show the relationships between sales, 
#land, and improvement values. Give this figure a good title.
property_sales <- read.csv(file.choose())
pairs(~Sales+Land.value+Improvement.value, 
      data=property_sales, main="Scatterplot matrix")
# 3-3-b Create a new column in the data frame named total which calculates the sum of land and improvement values.
#The new column is the total value of the property. Draw a scatterplot of sales in the y-axis vs total values in the x-axis.
#Give the figure a good title and axis labels.
property_sales$total <- property_sales$Land.value + 
                        property_sales$Improvement.value
plot(x=property_sales$total, y=property_sales$Sales, 
     main="Plot of sales vs total value",
     xlab="Total value", ylab="Sales")#è¿™æ®µè¦ç»™ä¸‹é¢å¤åˆ¶
# 3-3-c Using curve() function with the argument add=TRUE, 
#add a straight line ğ‘¦ =âˆ’16.5 + 1.36ğ‘¥ to the figure drawn in (b).
#Give this line a suitable colour and other properties to make it nicer.
#æŠŠä¸Šé¢é‚£æ®µå¤åˆ¶ï¼Œå†æ¥ç€
curve(-16.5+1.36*x, from=0, to=2500, add=TRUE, col="red", lty=2)#åŠ ä¸Šçº¿
# 3-3-d Add a legend in the top left corner of the figure, to show the line created in (c) is a fitted line.
#ä¸Šé¢å¤åˆ¶ï¼ŒåŒ…æ‹¬çº¿
legend("topleft", legend="fitted line", lty=2, col="red")#åŠ ä¸Šå›¾ä¾‹
# 3-3-f calculates the difference between the sales value and 
#the given straight line. Then, draw a histogram of the residuals,
# setting the y-axis to be the probability for each bin. Give this figure a good title.
residuals <- property_sales$Sales - (-16.5+1.36*property_sales$total)
hist(residuals, freq=FALSE)
# 3-3-g The code below gives the pdf of a Normal distribution with the given mean and 
#standard deviation. Using this function, add the pdf line in the histogram drawn in (d).
residuals <- property_sales$Sales - (-16.5+1.36*property_sales$total)
hist(residuals, freq=FALSE)#å¤åˆ¶ä¸Šé¢
curve(dnorm(x, mean=mean(residuals), sd=sd(residuals)), 
      from=-400, to=600, add=TRUE, col="red")







# T4
# 4-1-a Run the lines above and test whether the mean score for 
#class A students is greater than 70. State the null and alternative hypotheses.
TestScore <- read.csv(file.choose())
class_A <- subset(TestScore, Class=="A")
class_B <- subset(TestScore, Class=="B")
t.test(x=class_A$Score, mu=70, alternative="greater")
#ğ»0: ğœ‡ğ´ â‰¤ 70 vs ğ»1: ğœ‡ğ´ > 70
#where ğœ‡ğ´ is the mean score for class A.
#The R output shows that the test statistic is 2.4528 and ğ‘-value for the test is 0.03512.
#Since the ğ‘-value is less than ğ›¼ (0.05), we have enough evidence to reject the null hypothesis,
#and support the alternative hypothesis. We conclude that the mean score for class A is greater than 70.

# 4-1-b Test whether the variance of the scores of students in the two classes are equal. State the null and alternative hypothesis.
var.test(x=class_A$Score, y=class_B$Score)
#H0: ğœA^2 = ğœB^2 vs H1: ä¸ç­‰äº
# the ğ‘-value is 0.4462, which is greater than the significance level ğ›¼ = 0.05.
#Therefore there is not enough evidence to reject the null hypothesis. 
#We conclude that the two variances are equal.

# 4-1-c Test whether the mean GPA of students in Class A is equal to the mean GPA of students in Class B,
# assuming the variances are equal. State the null and alternative hypothesis.
t.test(x=class_A$GPA, y=class_B$GPA, var.equal=TRUE, 
       alternative="two.sided")
#ğ»0: ğœ‡ğ´ = ğœ‡B vs ğ»1: ğœ‡ğ´ â‰  ğœ‡B
#ğ‘-value is 0.2262,which is greater than the significance level ğ›¼.
#Therefore there is not enough evidence to reject the null hypothesis.

# 4-1-d Using one-way ANOVA, test whether 
#the  mean GPA of students in Class A is equal to the mean GPA of students in Class B.
#Compare the p-value of your test here with the p-value found in (c).
summary(aov(GPA ~ Class, data=TestScore))#H0=,H1ä¸ç­‰

# 4-1-e From the scatterplot, it is hypothesized that IQ can be used as a predictor for test score using the linear regression model.
#Fit the linear regression model using test score as the dependent variable and IQ as the independent variable.
#i Write down the fitted regression line.
plot(Score ~ IQ, data=TestScore)
model <- lm(Score ~ IQ, data=TestScore)
summary(model)
#ii Do the two variables test score and IQ have a significant linear relationship? Explain your answer.
#å¾—ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ = âˆ’6.4157 + 0.8882 Ã— ğ¼ğ‘„
#ğ‘-value for variable IQ is 0.00427, which is smaller than ğ›¼.
#Therefore, it can be concluded that the parameter related to IQ is non-zero,
# and that Score and IQ have a significant linear relationship.æœ‰å…³ç³»
# The ğ‘-value is for testing ğ›½1 = 0 vs ğ›½1 â‰  0 

# 4-2-a
#Using ğ‘¥1, ğ‘¥2, ğ‘¥3 and ğ‘¥4 as the predictors, 
#fit a linear regression model with ğ‘¦ as the response variable.
#Based on your results here, which predictors are significant to the model? 
#Use 10% significance level for your decision.
cement <- read.csv(file.choose())
model1 <- lm(y ~ x1 + x2 + x3 + x4, data=cement)
summary(model1)
#Based on the ğ‘-values, only the variable ğ‘¥1 has ğ‘-value less than ğ›¼ = 0.1
#Therefore, only ğ‘¥1seems to be significant to the model.ä¹Ÿå¯ä»¥çœ‹æ˜Ÿå·

# 4-2-b Now, using only ğ‘¥1and ğ‘¥2as the predictors, fit a linear regression model with ğ‘¦ as the response variable.
#Based on your results here, which predictors are significant to the model?
model2 <- lm(y ~ x1 + x2, data=cement)
summary(model2)
#After removing the variable ğ‘¥3and ğ‘¥4, the ğ‘-values for ğ‘¥1and ğ‘¥2are now very small. 
#Therefore, both of these variables (ğ‘¥1and ğ‘¥2) are significant to the model.

# 4-2-c Write down the fitted regression model using the result in (b).
# ğ‘¦ = 52.58 + 1.468ğ‘¥1 + 0.6623ğ‘¥2 ç³»æ•°å¯¹åº”Estimateåˆ—ï¼Œåœ¨åˆ†æç»“æœé‡Œ

# 4-2-d Using the model in (b) what is the estimated heat evolved in calories per gram of cement 
#when using 8% of tricalcium aluminate and 50% of tricalcium silicate?
# ç›´æ¥ä»£å…¥ï¼š ğ‘¦ = 52.58 + 1.468(8) + 0.6623(50) = 97.44 calories.

# 4-3-a
#Run the lines above and test whether the sales for properties in Cheval and Hyde Park 
#have the same variance. State the null and alternative hypotheses
property_sales <- read.csv(file.choose())
cheval_sale <- subset(property_sales, Neighbourhood=="Cheval")$Sales
hydepark_sale <- subset(property_sales, Neighbourhood=="HydePark")$Sales
var.test(cheval_sale, hydepark_sale)
#H0 ä¸ºä¸¤ä¸ªğœ^2ç­‰ï¼ŒH1ä¸ç­‰
# p-value is very small (2.2 Ã— 10âˆ’5), we have strong evidence to reject the 
#null hypothesis. We conclude that the two variances are not equal

# 4-3-b 
#Test whether the mean sales for properties in Cheval is smaller than the mean sales for 
#properties in Hyde Park, assuming that the variances for the two populations are not equal.
t.test(cheval_sale, hydepark_sale, alternative="less", var.equal=FALSE)
#"two.sided", "less", or "greater"
# p-value is smaller than ğ›¼ = 0.05, we reject the null hypothesis.

# 4-3-c
#Using one-way ANOVA, test whether the mean land values are equal for all four
#neighbourhoods. State the null and alternative hypotheses.
#Neighbourhoodåˆ—æœ‰å‡ ç§åå­—
summary(aov(Land.value~Neighbourhood, data=property_sales))
#The p-value from the ANOVA is very small. Therefore we reject the null hypothesis

# 4-3-d
#Using one-way ANOVA, test whether the mean improvement values are equal for all four neighbourhoods.
summary(aov(Improvement.value~Neighbourhood, data=property_sales))

# 4-3-e Using land and improvement values as the regressors or independent variables,
#fit a linear regression model to predict the sales using the two regressors.

#i) Write down the fitted regression model.
fit <- lm(Sales~Land.value+Improvement.value, data=property_sales)
summary(fit)

#ii) Based on the results, is land value significant in the linear model? Explain your answer.
#The land value is significant in the regression model æ˜¾è‘—
#since the p-value for the parameter related to the land value is very small.éå¸¸å°

#iii) What is the estimated sales price of a property with $100 000 land value (or equivalently Land.value=100) 
#and $200 000 improvement value (or equivalently Improvement.value=200)?
#ç›´æ¥ä»£å…¥100å’Œ200
#ğ‘†ğ‘ğ‘™ğ‘’ğ‘  = âˆ’16.176 + 1.393 Ã— 100 + 1.330 Ã— 200 = 389.124 = $389 124







# T5
# Write down a function named vector_mean that calculates the mean of a vector. 
#Compare your result with the function mean.
vector_mean <- function(x){
  n = length(x)
  output = sum(x)/n
  return(output)
}
#Example output:
vector_mean(c(1,2,3))
mean(c(1,2,3))

# The %% operator calculates the remainder when a number is divided by another number.
#For example, 3 %% 2 will return 1 while 4 %% 2 will return 0.
#Another name for this operation is the modulus operation where 3 mod 2 = 1.
##çœ‹æ˜¯ä¸æ˜¯æ•´å€æ•°
#Using this operator, write down a function that takes input two integer values, ğ‘ and ğ‘,
#and determine whether ğ‘ is a multiple of ğ‘.
#The function will return TRUE if ğ‘ is a multiple of ğ‘, and will return FALSE if ğ‘ is not a multiple of ğ‘.
#Note that if ğ‘ is a multiple of ğ‘, then ğ‘mod ğ‘ = 0.
multiple <- function(a,b){
  remainder <- a %% b
  if(remainder == 0){
    output=TRUE
  }
  if(remainder != 0){
    output=FALSE
  }
  return(output)
}
#Example output:
multiple(3,2)#(3,3),(27,5),(27,9)éƒ½è¯•è¯•

# Write a function that takes an input and calculate the square root of this input.
# The function should return two values, the solution and error check.
#If the input is not numerical or negative value, return NA as the solution, and error check is TRUE.
#Otherwise, return the square root of the input as the solution, and error check is FALSE.
#Note: remember to use list() to return multiple outputs.
square_root <- function(x){
  if(!is.numeric(x) | x<0){
    solution <- NA
    error <- TRUE
  } else {
    solution <- sqrt(x)
    error <- FALSE
  }
  return(list(solution=solution, error=error))
}
#Example output:
square_root("A")# 9,-9éƒ½è¯•è¯•

# Use the while loop to determine the number of terms required for the product 1 Ã— 2 Ã— 3 Ã— 4 Ã— â‹¯ reaches above 10 million.
i <- 0
product <- 1
while(product < 10000000){
  i <- i+1
  product <- product*i
}
print(i)
#ç¬¬11ä¸‹è¾“å‡º

# The Fibonacci numbers, denoted as ğ¹ğ‘›, is a sequence of numbers
#that starts with ğ¹1 = 1and followed by the second number ğ¹2 = 1.
#For ğ‘› â‰¥ 3, it is given that ğ¹ğ‘› = ğ¹ğ‘›âˆ’1 + ğ¹ğ‘›âˆ’2(æ³¨æ„næ˜¯ä¸‹æ ‡)
#Write down a function that will take input ğ‘› and return the first ğ‘› numbers of the Fibonacci numbers.
Fibonacci <- function(n){
  output <- rep(1,n)
  if(n > 2){
    for(i in 3:n){
      output[i] <- output[i-1] + output[i-2]
    }
  }
  return(output)
}
#Example output:
Fibonacci(1)#æ•°å­—éšä¾¿ææ

# Write a code using for loop that simulates the result of a die throw and
#calculates the sum of the numbers from 10 die throws.
#Note that the function sample can be used to randomly select a value out of the given input.
#For example sample(1:6, 1) will randomly select an integer between 1 to 6 with equal probability.
#ç­‰æ¦‚ç‡éšæœºé€‰æ‹©ä¸€ä¸ª1åˆ°6ä¹‹é—´çš„æ•´æ•°
summation <- 0
for(i in 1:10){
  die_value <- sample(1:6,1)
  summation <- summation + die_value
}
print(summation)

# The solutions to the quadratic equation ğ‘ğ‘¥^2 + ğ‘ğ‘¥ + ğ‘ = 0,
#Note that there is only one solution if ğ‘^2 âˆ’ 4ğ‘ğ‘ = 0 and the solution does not exist if ğ‘^2 âˆ’4ğ‘ğ‘ < 0
quadratic <- function(a, b, c){
  disc <- b^2 - 4*a*c
  if(disc==0){
    x <- -b/(2*a)
    number_solution <- 1
  } else if(disc>0){
    x1 <- (-b-sqrt(disc))/(2*a)
    x2 <- (-b+sqrt(disc))/(2*a)
    x <- c(x1,x2)
    number_solution <- 2
  } else{
    x <- NA
    number_solution <- 0
  }
  return(list(solution = x, number_of_solution = 
                number_solution))
}
#Example output:åˆ†åˆ«æ˜¯ä¸¤ä¸ªï¼Œä¸€ä¸ªï¼Œæ²¡æœ‰è§£
quadratic(1,0,-9)
quadratic(1,-6,9)
quadratic(1,0,9)

# You bought some stocks at a price of RM 1.00 per share.
#You decided to either cut your loss by selling the shares if the price goes to RM 0.75,
# or sell the shares for some profit if the price reaches RM 1.50.
#Assume that each day, the stock price may either decrease by 5 cents, 
#stay the same, or increase by 5 cents, with equal probability.
#
#Write a code that simulates your stock price each day and 
#determine how long it takes for the stock price to either reach RM 0.75 or RM 1.50.
#You can use sample(c(-0.05, 0,0.05), 1) to select a number between âˆ’0.05, 0, and 0.05 with equal probability.
#ä»¥ç›¸ç­‰çš„æ¦‚ç‡é€‰æ‹©-0.05ã€0å’Œ0.05ä¹‹é—´çš„æ•°å­—ã€‚
price <- 1
day <- 0
while(price < 1.5 & price > 0.75){
  price <- price + sample(c(-0.05,0,0.05),1)
  day <- day+1
}
print(day)







# T6
#Suppose ğ‘‹ and ğ‘Œ are independent random variables such that
#ğ‘‹ follows the Poisson distribution with mean 3, and ğ‘Œ follows the Poisson distribution with mean 4.
#
# Find the probability ğ‘ƒ(ğ‘‹ = 3).
dpois(3, lambda=3)
# Find the probability ğ‘ƒ(ğ‘‹ â‰¤ 3).
ppois(3, lambda=3)
# Generate 100 random samples of ğ‘Œ . Calculate its mean and variance. Compare these values 
#with the theoretical mean and variance of ğ‘Œ (mean(ğ‘Œ ) = var(ğ‘Œ ) = 4).
set.seed(100)
Y <- rpois(100, lambda=4)
mean(Y)
var(Y)

# In theory the random variable ğ‘ = ğ‘‹ + ğ‘Œ should follow the Poisson distribution with mean 7.
#Generate 1000 samples of ğ‘. Calculate its mean and variance.
#From your generated values of ğ‘, what is the estimated value for the probability ğ‘ƒ(ğ‘ =7)? 
#Compare your answer with the theoretical probability using Poisson distribution with mean 7.
generate_Z <- function(n){
  X <- rpois(n, lambda=3)
  Y <- rpois(n, lambda=4)
  Z <- X+Y
  return(Z)
}
set.seed(100)
Z <- generate_Z(1000)
mean(Z)
var(Z)
table(Z)/1000 # estimated probabilityä¼°è®¡æ¦‚ç‡
dpois(7, lambda=7) # theoretical probabilityç†è®ºæ¦‚ç‡
#From the generated ğ‘, we estimate ğ‘ƒ (ğ‘ = 7) to be 0.145. And as shown, the true value for ğ‘ƒ (ğ‘ = 7) is 0.149.

# One such approximation technique is called the Monte Carlo integration.
#
#Write a function f, where the function calculates ğ‘“(ğ‘¥) = x^x
f <- function(x){
  return(x^x)
}

#Write a function which takes input ğ‘›.
#The function will randomly generate ğ‘› samples of ğ‘‹ 
  #from the uniform distribution with min 1 and max 2.
  #The function then estimates the integral by calculating 1/ğ‘›âˆ‘(1åˆ°n)f(ğ‘‹ğ‘–)
  #The function will then return the estimate.
monte_carlo_int <- function(n){
  X <- runif(n, min=1, max=2)
  est <- 1/n*sum(f(X))
  return(est)
}

#Using the function written in (b), estimate the integral âˆ«(1åˆ°2)x^x dx
#Note: You can use the command â€œintegrate(f, 1, 2)â€ in R to approximate the integral
#using another approximation method (not Monte Carlo integration).
set.seed(100)
monte_carlo_int(100000)
integrate(f, 1, 2) # compare using built-in function
#We can compare the result from our Monte Carlo method with the built-in function to 
#integrate numerically in R which gives the value 2.050446, which is not far from our result.ç›¸ä¼¼ç›¸è¿‘

#The Beta(3,5) distribution has the probability density function (pdf)
#i) Generate a random value of ğ‘¥ using uniform distribution from 0 to 1.
#ii) Generate a random value of ğ‘¢ using uniform distribution from 0 to 2.4.
#iii) If ğ‘¢ â‰¤ ğ‘“(ğ‘¥) where ğ‘“(ğ‘¥) is the pdf of Beta(3,5), 
#then accept ğ‘¥ as a sample of Beta(3,5) distribution. Otherwise, reject it and repeat step (i) of the algorithm.
#
#Write a function that generates ğ‘› samples from Beta(3,5) distribution using the rejection sampling 
#algorithm. Then using your function, generate 1000 samples, plot a histogram of the samples, and 
#compare it to the pdf of Beta(3,5) distribution.
generate_x <- function(n){
  x <- c()
  n_accept <- 0
  while(n_accept < n){
    x1 <- runif(1, min=0, max=1)
    u <- runif(1, min=0, max=2.4)
    if(u <= dbeta(x1,3,5)){
      x <- c(x,x1)
    }
  }
  return(x)
}
set.seed(100)
x <- generate_x(1000)
length(x)
hist(x, freq=FALSE)
curve(dbeta(x,3,5), from=0, to=1, col="red", 
      add=TRUE)







# EX
#1-a
generate_X <- function(k) {
  # Starting position
  X <- 0
  
  # Simulate k steps
  for (i in 1:k) {
    # Randomly choose left (-1) or right (1) bounce with equal probability
    direction <- sample(c(-1, 1), 1)
    
    # Update the position based on the chosen direction
    X <- X + direction
  }
  
  return(X)
}
set.seed(123)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
result <- generate_X(10)  # å°çƒç»è¿‡10æ­¥åçš„ä½ç½®
print(result)


#1-b
generate_X_samples <- function(n, k) {
  # Initialize a vector to store the results
  results <- numeric(n)
  
  # Generate n samples of X after k steps
  for (i in 1:n) {
    results[i] <- generate_X(k)
  }
  
  return(results)
}
set.seed(123)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
samples <- generate_X_samples(5, 10)  # ç”Ÿæˆ5ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ç»è¿‡10æ­¥åçš„ä½ç½®
print(samples)


#1-c
# å®šä¹‰è®¡ç®—å‡å€¼å’Œæ–¹å·®çš„å‡½æ•°
calculate_mean_and_variance <- function(samples) {
  mean_value <- mean(samples)
  variance_value <- var(samples)
  return(c(mean_value, variance_value))
}

# ä¼°è®¡ k = 20 æ—¶çš„å‡å€¼å’Œæ–¹å·®
set.seed(123)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
samples_k20 <- generate_X_samples(1000, 20)  # ç”Ÿæˆ1000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ç»è¿‡20æ­¥åçš„ä½ç½®
result_k20 <- calculate_mean_and_variance(samples_k20)
print(paste("Mean for k = 20:", result_k20[1]))
print(paste("Variance for k = 20:", result_k20[2]))

# ä¼°è®¡ k = 30 æ—¶çš„å‡å€¼å’Œæ–¹å·®
set.seed(123)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
samples_k30 <- generate_X_samples(1000, 30)  # ç”Ÿæˆ1000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ç»è¿‡30æ­¥åçš„ä½ç½®
result_k30 <- calculate_mean_and_variance(samples_k30)
print(paste("Mean for k = 30:", result_k30[1]))
print(paste("Variance for k = 30:", result_k30[2]))


#1-d
#i
generate_X_samples_with_returns <- function(n, k, cost_per_play, reward_threshold, win_amount) {
  # Initialize vectors to store results(åˆå§‹åŒ–å‘é‡æ¥å­˜å‚¨ç»“æœ)
  positions <- numeric(n)
  returns <- numeric(n)
  
  # Generate n samples of X after k steps(kæ­¥åç”ŸæˆXçš„nä¸ªæ ·æœ¬)
  for (i in 1:n) {
    position <- generate_X(k)
    positions[i] <- position
    
    # Calculate return based on the position(æ ¹æ®ä»“ä½è®¡ç®—æ”¶ç›Š)
    if (position >= reward_threshold) {
      returns[i] <- win_amount
    } else {
      returns[i] <- 0
    }
  }
  
  # Deduct the cost of playing the game(æ‰£é™¤ç©æ¸¸æˆçš„è´¹ç”¨)
  returns <- returns - cost_per_play
  
  # Return a list containing positions and returns(è¿”å›åŒ…å«ä»“ä½å’Œæ”¶ç›Šçš„åˆ—è¡¨)
  return(list(positions = positions, returns = returns))
}

#ii
# ä¼°è®¡æ¸¸æˆåˆ©æ¶¦æˆ–äºæŸï¼Œk = 20
set.seed(123)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
game_results_k20 <- generate_X_samples_with_returns(1000, 20, 10, 8, 100)

# è®¡ç®—æ¸¸æˆçš„æ€»åˆ©æ¶¦æˆ–äºæŸ
total_profit_loss_k20 <- sum(game_results_k20$returns)
print(paste("Total profit/loss for k = 20:", total_profit_loss_k20))

# ä¼°è®¡æ¸¸æˆåˆ©æ¶¦æˆ–äºæŸï¼Œk = 30
set.seed(123)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
game_results_k30 <- generate_X_samples_with_returns(1000, 30, 10, 8, 100)

# è®¡ç®—æ¸¸æˆçš„æ€»åˆ©æ¶¦æˆ–äºæŸ
total_profit_loss_k30 <- sum(game_results_k30$returns)
print(paste("Total profit/loss for k = 30:", total_profit_loss_k30))





#2-a
proportion_within_interval <- function(data, k) {
  # Calculate mean and standard deviation of the data
  # è®¡ç®—æ•°æ®çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®
  x_bar <- mean(data)
  s <- sd(data)
  
  # Define the interval
  # å®šä¹‰é—´éš”
  lower_limit <- x_bar - k * s
  upper_limit <- x_bar + k * s
  
  # Count the number of data points within the interval
  # ç»Ÿè®¡åŒºé—´å†…æ•°æ®ç‚¹çš„ä¸ªæ•°
  within_interval <- sum(data >= lower_limit & data <= upper_limit)
  
  # Calculate the proportion within the interval
  # è®¡ç®—åŒºé—´å†…çš„æ¯”ä¾‹
  proportion <- within_interval / length(data)
  
  return(proportion)
}
# Generate a sample data set
# ç”Ÿæˆä¸€ä¸ªç¤ºä¾‹æ•°æ®é›†
set.seed(123)
sample_data <- rnorm(100, mean = 10, sd = 2)

# Use a function to calculate the proportion of data in the range xÌ… Â± ks, where k =2
# ä½¿ç”¨å‡½æ•°è®¡ç®—åœ¨ xÌ… Â± ks èŒƒå›´å†…çš„æ•°æ®æ¯”ä¾‹ï¼Œè¿™é‡Œ k = 2
proportion_within_2sd <- proportion_within_interval(sample_data, 2)
print(paste("Proportion within 2 standard deviations:", proportion_within_2sd))


#2-b
# Generate 100 samples from a standard normal distribution of length 10,000
# ç”Ÿæˆ100ä¸ªé•¿åº¦ä¸º10,000çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„æ ·æœ¬
set.seed(123)
random_samples <- matrix(rnorm(100 * 10000), nrow = 100)

# Define a function to check the validity of Chebyshev's theorem
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ£€æŸ¥Chebyshevå®šç†çš„æœ‰æ•ˆæ€§
check_chebyshev <- function(samples, k) {
  proportions <- apply(samples, 1, proportion_within_interval, k = k)
  return(proportions)
}

# Check the validity of Chebyshev's theorem under different values of k
# æ£€æŸ¥Chebyshevå®šç†åœ¨ä¸åŒkå€¼ä¸‹çš„æœ‰æ•ˆæ€§
k_values <- c(2, 3, 4)  # é€‰æ‹©ä¸åŒçš„kå€¼(Choose different k values)
results <- lapply(k_values, function(k) check_chebyshev(random_samples, k))

# è¾“å‡ºç»“æœ
for (i in seq_along(k_values)) {
  cat("Proportion within", k_values[i], "standard deviations:", mean(results[[i]]), "\n")
}


#2-c
# Generate 100 uniformly distributed samples of length 10,000
# ç”Ÿæˆ100ä¸ªé•¿åº¦ä¸º10,000çš„å‡åŒ€åˆ†å¸ƒçš„æ ·æœ¬
set.seed(123)
uniform_samples <- matrix(runif(100 * 10000), nrow = 100)

# Check the validity of Chebyshev's theorem for different values of k (using uniform distribution)
# æ£€æŸ¥Chebyshevå®šç†åœ¨ä¸åŒkå€¼ä¸‹çš„æœ‰æ•ˆæ€§ï¼ˆä½¿ç”¨å‡åŒ€åˆ†å¸ƒï¼‰
results_uniform <- lapply(k_values, function(k) check_chebyshev(uniform_samples, k))

# è¾“å‡ºç»“æœ(Output results)
for (i in seq_along(k_values)) {
  cat("Proportion within", k_values[i], "standard deviations (Uniform distribution):", mean(results_uniform[[i]]), "\n")
}
